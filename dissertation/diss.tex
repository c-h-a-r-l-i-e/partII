% Template for a Computer Science Tripos Part II project dissertation
\documentclass[12pt,a4paper,twoside,openright]{report}
\usepackage[pdfborder={0 0 0}]{hyperref}    % turns references into hyperlinks
\usepackage[margin=25mm]{geometry}  % adjusts page layout
\usepackage{graphicx}  % allows inclusion of PDF, PNG and JPG images
\usepackage{verbatim}
\usepackage{pdfpages}
\usepackage{caption}
\usepackage{subcaption}


\raggedbottom                           % try to avoid widows and orphans
\sloppy
\clubpenalty1000%
\widowpenalty1000%

\renewcommand{\baselinestretch}{1.1}    % adjust line spacing to make
                                        % more readable

\begin{document}

\bibliographystyle{plain}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Title


\pagestyle{empty}

\rightline{\LARGE \textbf{Charlie Maclean}}

\vspace*{60mm}
\begin{center}
\Huge
\textbf{Synthesis of Heart-Rate Detection Methods} \\[5mm]
Computer Science Tripos -- Part II \\[5mm]
King's College \\[5mm]
\today  % today's date
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Proforma, table of contents and list of figures

\pagestyle{plain}

\chapter*{Proforma}

{\large
\begin{tabular}{ll}
Name:               & \bf Charlie Maclean                       \\
College:            & \bf King's College			\\
Project Title:      & \bf Synthesis of Heart-Rate Detection Methods	 \\
Examination:        & \bf Computer Science Tripos -- Part II, July 2020  \\
Word Count:         & \bf TODO\footnotemark[1]		\\
Project Originator: & Dr Robert Harle                   \\
Supervisor:         & Dr Robert Harle                   \\ 
\end{tabular}
}
\footnotetext[1]{This word count was computed
by \texttt{detex diss.tex | tr -cd '0-9A-Za-z $\tt\backslash$n' | wc -w}
}
\stepcounter{footnote}


\section*{Original Aims of the Project}

To research and implement the detection of heart rate from smartwatch 
sensors. To investigate the effectiveness of a selection of filters and 
peak finding algorithms. To use accelerometer data to find motion artifacts
within the data, and compare methods of removing these artifacts.


\section*{Work Completed}

All that has been completed appears in this dissertation.

\section*{Special Difficulties}

Learning how to incorporate encapulated postscript into a \LaTeX\
document on both Ubuntu Linux and OS X.
 
\newpage
\section*{Declaration}

I, Charlie Maclean of King's College, being a candidate for Part II of the 
Computer Science Tripos, hereby declare that this dissertation and the work 
described in it are my own work, unaided except as may be specified below, 
and that the dissertation does not contain material that has already been 
used to any substantial extent for a comparable purpose.

\bigskip
\leftline{Signed [signature]}

\medskip
\leftline{Date [date]}

\tableofcontents

\listoffigures

\newpage
\section*{Acknowledgements}

This document owes much to an earlier version written by Simon Moore
\cite{Moore95}.  His help, encouragement and advice was greatly 
appreciated.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% now for the chapters

\pagestyle{headings}

\chapter{Introduction}

Elite runners have historically used heart rate to provide an accurate 
measure of fitness, and allow them to train more effectively. [Expand on uses
of heart rate]. Previously, Electrocardiography (ECG) chest straps have been 
used to measure heart rate, by detecting the electrical signals controlling 
the expansion and contraction of the heart. They are accurate devices however
often prohibitively expensive, and hence inaccessible to casual runners.

In recent years, a new technology has emerged - Photoplethysmogram (PPG) 
- light is directed at the skin, and sensors measure how much blood vessels
scatter it. PPG sensors are cheaper than ECG sensors, and hence are 
available in a variety of products, particularly smartwatches. This 
innovation has bought a new wave of advanced training and monitoring onto
the wrists of any runner.

Switching from ECG to PPG is not without flaws though - ECG sensors return a
clean signal, as opposed to PPG signals which are contaminated with
noise. [More details about noise]. 

In particular when running, the motion can cause blood velocity to 
change, and the sensor can slip across the skin \cite{Wijshoff17}, 
\cite{Wood06}. These result in a distortion to the PPG signal, known as a
motion artifact (MA). Fortunately, smartwatches contain other sensors, such
as accelerometers and gyroscopes which can be used to predict the presence of 
MAs, and hence compensate for them.

My task is to research and develop a heart rate detection algorithm
for smartwatches worn during running. 

\chapter{Preparation}

This chapter details the steps I took to determine how to develop my
implementation. It first describes photoplethysmography, the method with which heart-beats are
detected on watches. Next,
I give an overview of the algorithms I will use to extract the heart-rate from
the PPG signal: filters, peak-detectors and motion artefact removers. Finally, I
outline my development methodology.

\section{Photoplethysmography (PPG)}

To develop an algorithm to track heart-rate on wrist-watches it is first important to
understand how watches track heart activity. PPG is a technique where light is
used to detect the volume of blood in veins. In hospitals, this is used in
finger pulse oximeters (Figure \ref{fig:fingerppg}) to record the heart-beat
of patients. These work by transmitting light on one side of the finger, and
then measuring how much light is received on the other side of the finger.
The amount of light which permeates through the finger is related to how much
blood is currently in the veins.


\begin{figure}[h!]
	\centerline{\includegraphics[width=0.3\textwidth]{figs/fingerppg.jpg}}
	\caption{Finger pulse oximeter. Image source \cite{wiki:fingerppg}.}
\label{fig:fingerppg}
\end{figure}

With watches, we cannot transmit light on one side, and
receive light on the other side, as the wrist is far too large. Hence, instead
of monitoring the absorption of light by the skin, we monitor the reflection
of light by the skin. A light is shone into the wrist, and sensors nearby
monitor how much is reflected back. When the wrist is full of blood, more
light is reflected back as blood scatters lights.

We know now how the signals are recorded, but we have not yet explored the
signal that is actually received from this technique. In Figure
\ref{fig:typicalppgsignal} we see a
clean PPG recording. There are two peaks in the data - a sytolic peak and a
diastolic peak. The systolic peak represents the point at which the heart has
beat - and hence pushed blood through the body. The challenge is to find this
peak.

\begin{figure}[h!]
	\centerline{\includegraphics[width=0.7\textwidth]{figs/typicalppgsignal.jpeg}}
	\caption{Example PPG signal. Image and annotations from \cite{elgendi12}.}
\label{fig:typicalppgsignal}
\end{figure}

\section{Filtering}

PPGs produce a large amount of noise from various sources:
\begin{itemize}
	\item Light pollution. Both DC and AC lights in the environment can
		infiltrate the sensor, affecting the PPG signal \cite{kim15}.
	\item Temperature. As temperature increases, so does the volume of
		blood, which will be picked up by the PPG sensor 
		\cite{shin16}.
	\item Breathing. The change in pressure accosiated with respiration
		causes variations in the flow of blood, and hence can be seen
		by the PPG sensor \cite{allen02}.
\end{itemize}

In order to remove much of this noise, we can use filters to remove
frequencies we know are irrelevant. We know the heartbeat can vary from 
30 to 220 beats per minute, and hence we would like to disregard any noise 
outside of this range. In this section, I will introduce the concept of 
filters, and describe two filters useful for PPG signals.

\begin{figure}[h!]
	\centerline{\includegraphics[width=0.8\textwidth]{figs/filter.png}}
\caption{Diagram showing filter characteristics}
\label{fig:filterdiag}
\end{figure}

Figure \ref{fig:filterdiag} displays an example filter magnitude response
diagram. This plots the amount of gain applied to each frequency. A gain of
zero means the signal is removed, a gain of one means the signal is unchanged.
The characteristics displayed are as follows.

The passband is the range of frequencies we would like to remain. In an ideal
filter, there is no loss within the passband.

Passband ripple describes the variation in amplitude \emph{within} the
passband. An ideal filter will have no passband filter, such that all
frequencies within the passband are permitted equally.

The transition width is the frequency range between the start and stop band.
Ideally, this is zero, such that frequencies outside of the passband are
instantly reduced.

The stopband is the range of frequencies we wish to remove. An ideal filter
completely removes all frequencies within the stopband.

The ideal filter, as described above, is impossible - and hence we have a
variety of filters which compromise between the desirable characteristics.
Following this, I detail two of these compromises - the Butterworth filter,
and the Chebyshev filter.


\subsection{Butterworth Filter}

The Butterworth filter aims to minimize passband ripple, at the expense of a
larger transition width. To define a Butterworth filter, multiple parameters
are used, which I will describe further here.

\begin{figure}[h]
	\centerline{\includegraphics[width=0.8\textwidth]{figs/butter-order-comparison.png}}
\caption{Comparison of Butterworth filter orders}
\label{fig:butterworth-order}
\end{figure}

Order (\(N\)) controls the transition width - the higher the order, the lower
the transition width. This is desirable - we want to keep the passband as
large as possible, and transition quickly to the stopband. However, it comes
at the cost of computation complexity, as higher order filters take longer to
apply. See figure \ref{fig:butterworth-order} for a plot displaying the effect
of different orders on a filter's response.

Critical frequency gives the frequency at which we want gain to drop below
\(1/\sqrt2\) from the passband. Hence we use this parameter to define the
point from which we wish to cut out noise. Figure \ref{fig:butterworth-order}
uses critical frequencies 0.4 and 4 hz, which correspond to 24 and 240 bpm, a
reasonable heart rate range.

Type describes which frequencies we cut out. There are four different
types of Butterworth filters, as follows:

\begin{itemize}
	\item Lowpass - allow frequencies below the critical frequency.

	\item Highpass - allow frequencies above the critical frequency.

	\item Bandpass - combination of lowpass and highpass - given two
		frequencies, we want the passband to be between those
		frequencies.

	\item Bandstop - given two frequencies, put the stopband between them,
		leaving the passband outside those frequencies.
\end{itemize}

We will be using a bandpass filter, as there is low and high frequency noise
we wish to remove.

\subsection{Chebyshev Filter}

The Chebyshev filter aims to reduce the transition width as much as possible,
but to do this it introduces increased ripple.

\begin{figure}[h]
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=\linewidth]{figs/cheby1-rp-comparison.png}
  \caption{Chebyshev Type 1}
  \label{fig:cheby1rs}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=\linewidth]{figs/cheby2-rp-comparison.png}
  \caption{Chebyshev Type 2}
  \label{fig:cheby2rs}
\end{subfigure}
\caption{Comparison of Chebyshev filter rs values}
\label{fig:chebyrs}
\end{figure}

The filter is defined with similar parameters to a Butterworth filter - order,
critical frequencies, and type all have very similar meanings. However,
there are type 1 and 2 Chebyshev filters, with different aims. Additionally,
there is a new parameter \emph{rs}. I will explain these differences here.

Type 1 Chebyshev filters introduce passband ripple, whereas type 2 Chebyshev 
filters introduce stopband ripple. Figure \ref{fig:chebyrs} shows how these
differences manifest in the response of a second order Chebyshev filter.

The parameter \emph{rs} is defined as the maximum ripple permitted below unity
gain. Higher \(rs\) results in more ripple for a type 1 filter, but less
ripple for a part 2 filter, as is demonstrated in figure \ref{fig:chebyrs}.
Introducing more ripple is undesirable as leads to more signal distortion,
however can be advantageous as it reduces the transition width.

\section{Heart Rate Calculation}

Now we have removed noise from the signal, we should have a signal 
representing the volume of blood in veins within the arm. As the heart beats,
it sends a wave of blood through the body, forcing more blood through these
veins. Hence, peaks in the PPG signal correspond to heart beats. 

There are multiple approaches to finding heart-rate from our filtered
signals, and I will detail a few here.

\subsection{Local Maxima}

If we can find the peaks in the signal, we can count them up and divide by the
time period we count those peaks within, giving us a heart rate. One way we
can define peaks is as local maxima.

The local maxima in a signal are defined as samples which are larger than both
neighbouring samples. Finding local maxima is an easy problem to solve - 
intuitively, we can create an algorithm which iterates through the samples,
comparing each sample to it's neighbours, which has complexity \(O(n)\).

\subsection{Peak-Peak Standard Deviation Minimization}

Finding the local maxima is a naive approach that doesn't adapt to any problem
specific knowledge. For example, we know heart-rate will not climb above 220
bpm, however the prior solution could report 300 bpm. Additionally, it might
find multiple local peaks around a single heart-beat. 

Ideally, we want to include knowledge about what a normal heart-beat looks
like in our detection algorithm. One thing we can do is look at peak-peak
intervals - the time that passes between heart beats. Surprisingly, this is
normally not consistent - a healthy heart actually beats with some
variation. However, when running it has been found that the heart beats with
very little variation \cite{michael17}, and hence in our case we can assume that the heart
beats regularly. The aim of this method is to use this assumption, along with
minimum and maximum heart-rate to better detect heart-beats.

The method begins by calculating an initial set of peaks, by calculating the
rolling mean of the signal, and marking points above that mean as peaks. Then,
we compute the standard deviation of the time between these peaks (peak-peak
interval). Then, we iteratively increase the rolling mean and again calculate
the peaks, along with
the standard deviation of their intervals. The idea is every time we increase the rolling mean we 
exclude more peaks. Then at the end, the peaks we actually select are the peaks which give a reasonable
heart-rate (in the range 20-240 bpm), and have the smallest standard deviation.

So, we have developed an algorithm that attempts to find a heart-beat with
regular peak-peak intervals, and is within a reasonable range.


\subsection{Kalman Filter (extension)}

So far, we have not considered previous heart-rate readings when considering
the current calculation. This is naive, as heart-rate over the course of a run
follows a very fixed pattern. 

Figure    shows heart-rate over a steady run. It is clear initially heart-rate
ramps up until it reaches a 'steady-state'. From here on the heart-rate
remains pretty constant, not responding to slight changes in exertion.
Finally, the heart-rate decreases rapidly once the run has completed.

The Kalman filter is an algorithm which can compensate for noisy and
inaccurate measurements such as what we get from the PPG signal. It consists
of two phases:
\begin{enumerate}
	\item Prediction step - predict the current heart rate based on the
		previous heart rate, and some model. In this step we can
		incorporate the accelerometer as a reasonable estimator for
		the change in running effort.

	\item Update step - take the actual reading from the PPG signal and combine
		with the output of the prediction step.
\end{enumerate}

The Kalman filter relies on modelling current heart-rate as a Gaussian
distribution with it's standard deviation representing the certainty of the
current estimate.

Kalman gain is the parameter used to weight the measurements against the
prediction. A higher gain assigns more trust to the measurements, meaning the
filter will respond quicker, a low gain produces more smoothing.

\section{Motion Artefact Reduction}

In this section I explore a method which can be used to reduce the effect of 
Motion Artefacts (MAs) on the PPG Signal.

\subsection{Adaptive Noise Cancellation}

Adaptive Noise Cancellation (ANC), as described by Widrow et al.
\cite{Widrow75}, is a technique which allows us to remove noise from a signal,
given we have another signal correlated to the noise in some way. In our 
situation, we know MAs are correlated to motion, so we can use the 
accelerometer to remove MAs. This technique is extremely useful, as it can 
still produce good results when the MAs are at the same frequency as the heart
beat, even if the MAs have a larger amplitude.

%TODO: https://ieeexplore.ieee.org/abstract/document/7867772 this may be
%helpful


\begin{figure}[tbh]
	\centerline{\includegraphics[width=\textwidth]{figs/ANC-concept.png}}
\caption{ANC overall flow}
\label{epsfig}
\end{figure}


An overview of the algorithm follows. We have signal from heartbeat \(s\) that
we want to figure out, but this is contaminated by noise from MAs \(n_0\).
We assume the PPG sensor reading \(p\) is such that \(p=s+n_0\). Additionally,
we have accelerometer sensor readings \(n_1\). We filter \(n_1\), producing
signal \(y\) and subtract this from \(p\), to produce \(z=p-y\). Our aim is to
adjust the filter, such that \(y\) is as close to \(n_0\) as possible. 

The type of filter we adjust is known as a Finite Impulse Response (FIR)
filter. An \(N\)th order filter is defined by \(N\) weights.
These weights are convolved with the signal, hence filtering it.

The adaptive filter aims to choose a filter such that the power of the output 
\(E[z^2]\) is minimized. Given \(s\) is uncorrelated with \(n_0\) and \(n_1\), and \(n_0\)
is correlated with \(n_1\), it can be proven that minimizing the output power
is equivalent to finding \(z=s\).

There are multiple algorithms which exist in order to adaptively filter a
signal. I'll look at two, first describing the least mean squares (LMS) algorithm from
Widrow and Hoff. LMS first initializes all of the filter weights to 0. At each
step, it finds the gradient of the mean square output \(E(z^2)\).
Each weight's gradient describes what would happen to the signal if we kept
using that weight value. So if the gradient of a weight is positive we know
that using that weight again would increase the mean squared output. Hence, at
the end of each step we shift the weights down if the gradient is positive,
and visa versa if the gradient is negative.

LMS takes a parameter - step size \(\mu\), which scales how much we move the
weights by. The equation used to update weights is \[w_{n+1}=w_n-\mu \nabla
E(y^2)[n]\]
where \(W_n\) is the \(n\)th filter weight, and \(\nabla E(y^2)[n]\) is the
\(n\)th weight gradient.

Step size must be chosen very carefully, as if it is too large there is a risk
of LMS missing the solution as it overcompensates for the gradient. If it is
too small, then the algorithm becomes too expensive as we need many more
iterations. The situation is made worse as the ideal step size changes with
respect to the power of the input, making it very difficult to choose a step
size which gives stability.

To solve these stability issues, NLMS was introduced. It is the same as LMS, except you normalize the input power each
iteration. This makes choosing a step size which gives stability a lot easier.

So now we have a stable adaptive filter, which will allow us to tune a filter
that will remove motion noise from our PPG signal.


\section{Development Strategy}

I implemented the project in phases:

\begin{enumerate}
	\item Develop an application to collect PPG signal from watch while
		running.

	\item Collect data over the course of different runs. Import data into
		Python, to allow analysis.

	\item Implement filters in Python to remove miscellaneous noise.

	\item Implement heart-rate detectors in Python to extract the
		numerical heart-rate.

	\item Implement motion-artifact reduction algorithm to cancel out
		motion related noise.


\end{enumerate}

\chapter{Implementation}

\section{Gathering Data}

In this section I detail the process of developing an
application to record PPG data on a Wear OS watch. This turned out to be more
complicated than I presumed due to interesting issues inherent with developing for a small
wearable with limited power.

\subsection{Wear OS Development}

\paragraph{Language Choices}

The watch application was developed using the official IDE for Android
development - Android Studio. I programmed in a language I'd never used before
- Kotlin. Kotlin is an open source language based on Java, which aims to
reduce boilerplate code, adds null-safety, and remains interoperable with
Java, allowing libraries written for Java to be used in Kotlin.

\paragraph{Structure}

The program was split into classes as in Figure \ref{fig:classes}. The
behaviour of each class is as follows:

\begin{itemize}
	\item \emph{MainActivity} - central class responsible for starting,
		stopping and saving the recordings.

	\item \emph{SensorListener} - interface which overrides the Android
		\emph{SensorEventListener}. Contains methods which
		are called by the WearOS system whenever new sensor data comes
		in. Additionally contain methods which save the received data.
		We need one child for each sensor as each different sensor
		provides different data, and must be saved in a different
		format. So we have the following children:

	\begin{itemize}
		\item \emph{PpgListener}
		\item \emph{AccelerometerListener}
		\item \emph{RotationListener}
	\end{itemize}

\end{itemize}

When the user presses start recording, \emph{MainActivity} registers each
\emph{SensorListner} with the OS so they receive any sensor changes.

When the user presses stop recording, \emph{MainActivity} unregisters the
listners and gets each one to save their recording.

\paragraph{Storing Recordings}

It was critical that I could easily import the recordings into any program, and
hence I chose to export the data into a CSV text file. Each \emph{Listener}
class uses a \emph{CSVWriter} object from library \emph{opencsv} to write to a
unique file for each sensor, within a directory chosen by \emph{MainActivity}.
For example, at the end of the recording in the directory
\emph{YYYY-MM-DD/HH.MM.SS/} we have files \emph{ppg.csv},
\emph{accelerometer.csv} and \emph{rotation.csv}.

\paragraph{Interface}

I chose a simple yet functional interface to allow the user to start and stop
a recording. The interface changes colour when recording, which makes it very
easy to verify the recording is happening. Pictures of interface in Figure
\ref{fig:interface}.

\paragraph{Problems}

After I'd developed the application and was testing it out I found two key
issues which I will explain here.

\subparagraph{Power Saving}

Power is an enormous issue on wearable devices, as the form factor drastically
constrains the size of the battery. Hence developers have explicitly designed
Wear OS to limit power usage of any application as much as possible. 
As part of these optimisations Wear OS automatically suspends any application
if it thinks they are not being used. While this is useful for most users, my
application needs to run continuously without interruption.

Initially in testing there were long periods of time where no sensor values
were being recorded, due to the application being suspended.

To fix this issue, a wake lock was included. Once a wake lock is acquired, the
OS does not suspend the application. I added one which is acquired every time
a recording is started, and released when the recording ends.

\subparagraph{Sampling Rate}


\subsection{Uploading Recordings}

Now data has been recorded, the values must be uploaded somewhere to enable
later analysis. I created a server which would run on a Raspberry Pi that the
watch could connect to over the local network. The files would be passed to
the server, and from there the files are uploaded to Google Drive where they
can be accessed anywhere. In this section I go over the details of this
implementation. See figure \ref{fig:upload} for the overall uploading process.

\begin{figure}[tbh]
	\centerline{\includegraphics[width=\textwidth]{figs/upload.png}}
	\caption{The overall process of uploading files.}
	\label{fig:upload}
\end{figure}

\subsubsection{Changes to Wear OS Application}

First a 'sync' button was included in the interface, which users can press to
trigger the sending of files to the server.

Then I added the logic to be triggered when the button is pressed. This logic
iterates through every file in the recordings directory and performs a HTTP
PUT request with them. I used\ldots

\subsection{Raspberry Pi Access Point}

To connect the watch to the server I needed to create a local access point on the
Raspberry Pi. The
packages I used to do this were \emph{hostapd} and \emph{dnsmasq}. 

The package \emph{hostapd} is used to setup the access point, so I used it to configure
the name you can find the network from, the password of the network and the
channel it can be accessed on. 

The package \emph{dnsmasq} is used to setup the DHCP service, assigning IP
addresses to devices. I set it up to assign the range of adresses from 192.168.0.1 to
192.168.0.255 on the same interface as \emph{hostapd} is broadcasting over.

\subsubsection{Flask Web Application on Raspberry Pi}

Now, to setup the server I used Flask, a Python Web App framework. I chose
this over other frameworks like Django as it provides a flexible framework
which is easy to understand and deploy.

I created an application \emph{server.py} which
accepts PUT requests containing a file from URL \emph{/upload/path} where
\emph{path} is the location we want to place the file. Then, the server
makes the directories up to \emph{path} if they don't exist, placing the file
in this directory. Unlike in a normal server implementation, I do not secure
this file upload process. I am aware there are a number of security issues
concerned with leaving a file upload with arbitrary path options, for example
a user might be able to upload a file in the parent direction by placing a PUT
request for \emph{/upload/../../example}. However, I do not worry about these
attacks as the access point is secured by \emph{hostapd} and only the watch
will be connected.

Once the file has been saved, I upload the new file to google drive, by
calling \emph{gdrive.py}, which I detail below.

\subsubsection{Python Scripts to Upload to Google Drive}

To manage the process of uploading files to Google Drive, I created a new
application \emph{gdrive.py}. To upload to Google Drive using Python, I used
the library \emph{googleapiclient}, which was a surprisingly complicated API,
as I will explain here.

First, to connect to Google servers, the API must authenticate to ensure that
it has permission to access a user's Drive. The service requires a credential
token which expires periodically. Hence, I store the credentials in a binary
file using library \emph{pickle}, and when I need to access them, I 
refresh them if they have expired.

Then, I must actually upload a file. This process is complicated as Google
Drive does not use a path system to store files. Instead, it is a set of files
each with a unique IDs. A folder is simply a file with a \emph{folder} file
type, and a collection of files associated with it. Additionally, the only
methods available in the API 


\subsection{Synchronising Signals}

Once I have collected the PPG signal from the watch, and have recorded the ECG
from the chest, I need a method to synchronise the signals, such that they
start at the same time and we can compare them accurately.

I set out to produce a solution with the following properties:
\begin{itemize}
	\item Able to synchronize signals with \(\pm0.3\)s accuracy. With a
		heartbeat of 200 bpm this represents being within a heartbeat.
		This is an acceptable level of delay, as heart rate is
		averaged over several beats anyway.

	\item Can synchronize signals given the two recordings are started
		within two minutes of each other. This constraint is helpful
		as it prevents wasted time searching through the signal.

	\item Does not use the clocks built into the device. We must assume
		the clock within the ECG is unreliable. Additionally, the two
		devices may be synchronized to different time, and hence could
		be out by any amount of time.
\end{itemize}

Given I know both devices have an accelerometer, I realised I could ask the
wearer to move in some motion which is picked up by both devices. Then, I
could compare the two accelerometer signals in order to discover the
movement. Then comparing the starting times of the two signals would enable
calculation of the time difference between them.

The type of motion I chose was important, as it had to be easy to explain to
the wearer, but also provide sufficient motion for it to be identifiable
against normal motion. I decided jumping was appropriate -
I would ask the wearer to hold the watch close to their chest and jump three
to five times.

The cross correlation of two signals \(f\) and \(g\) is a measure of
similarity as a function of the displacement between them. It is simple to
calculate, as a sum of the products between the samples of \(f\) and of \(g\)
displaced by \(n\).

To synchronise the accelerometer, I developed the following three step 
algorithm:
\begin{enumerate}
	\item Normalize signals, by moving to zero mean, 

	\item Crop PPG signals to two minutes, crop ECG signals to four
		minutes, compute cross correlation with \(f=\) PPG
		acceleration, \(g=\) ECG acceleration.

	\item Compute the other way - crop ECG to two minutes, PPG to four
		minutes, compute cross correlation with \(f=\) ECG
		acceleration, \(g=\) PPG acceleration. This is 

	\item Find the maximum cross correlation across 

\end{enumerate}


\section{Filtering}

PPGs produce a large amount of noise from various sources:
\begin{itemize}
	\item Light pollution. Both DC and AC lights in the environment can
		infiltrate the sensor, affecting the PPG signal \cite{kim15}.
	\item Temperature. As temperature increases, so does the volume of
		blood, which will be picked up by the PPG sensor 
		\cite{shin16}.
	\item Breathing. The change in pressure accosiated with respiration
		causes variations in the flow of blood, and hence can be seen
		by the PPG sensor \cite{allen02}.
\end{itemize}

In order to remove much of this noise, we can use filters to remove
frequencies we know are irrelevant. We know the heartbeat can vary from 
30 to 220 beats per minute, and hence we would like to disregard any noise 
outside of this range. In this section, I will introduce the concept of 
filters, and describe two filters useful for PPG signals.

\begin{figure}[h!]
	\centerline{\includegraphics[width=0.8\textwidth]{figs/filter.png}}
\caption{Diagram showing filter characteristics}
\label{fig:filterdiag}
\end{figure}

Figure \ref{fig:filterdiag} displays an example filter magnitude response
diagram. This plots the amount of gain applied to each frequency. A gain of
zero means the signal is removed, a gain of one means the signal is unchanged.
The characteristics displayed are as follows.

The passband is the range of frequencies we would like to remain. In an ideal
filter, there is no loss within the passband.

Passband ripple describes the variation in amplitude \emph{within} the
passband. An ideal filter will have no passband filter, such that all
frequencies within the passband are permitted equally.

The transition width is the frequency range between the start and stop band.
Ideally, this is zero, such that frequencies outside of the passband are
instantly reduced.

The stopband is the range of frequencies we wish to remove. An ideal filter
completely removes all frequencies within the stopband.

The ideal filter, as described above, is impossible - and hence we have a
variety of filters which compromise between the desirable characteristics.
Following this, I detail two of these compromises - the Butterworth filter,
and the Chebyshev filter.


\subsection{Butterworth Filter}

The Butterworth filter aims to minimize passband ripple, at the expense of a
larger transition width. To define a Butterworth filter, multiple parameters
are used, which I will describe further here.

\begin{figure}[h]
	\centerline{\includegraphics[width=0.8\textwidth]{figs/butter-order-comparison.png}}
\caption{Comparison of Butterworth filter orders}
\label{fig:butterworth-order}
\end{figure}

Order (\(N\)) controls the transition width - the higher the order, the lower
the transition width. This is desirable - we want to keep the passband as
large as possible, and transition quickly to the stopband. However, it comes
at the cost of computation complexity, as higher order filters take longer to
apply. See figure \ref{fig:butterworth-order} for a plot displaying the effect
of different orders on a filter's response.

Critical frequency gives the frequency at which we want gain to drop below
\(1/\sqrt2\) from the passband. Hence we use this parameter to define the
point from which we wish to cut out noise. Figure \ref{fig:butterworth-order}
uses critical frequencies 0.4 and 4 hz, which correspond to 24 and 240 bpm, a
reasonable heart rate range.

Type describes which frequencies we cut out. There are four different
types of Butterworth filters, as follows:

\begin{itemize}
	\item Lowpass - allow frequencies below the critical frequency.

	\item Highpass - allow frequencies above the critical frequency.

	\item Bandpass - combination of lowpass and highpass - given two
		frequencies, we want the passband to be between those
		frequencies.

	\item Bandstop - given two frequencies, put the stopband between them,
		leaving the passband outside those frequencies.
\end{itemize}

We will be using a bandpass filter, as there is low and high frequency noise
we wish to remove.

\subsection{Chebyshev Filter}

The Chebyshev filter aims to reduce the transition width as much as possible,
but to do this it introduces increased ripple.

\begin{figure}[h]
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=\linewidth]{figs/cheby1-rp-comparison.png}
  \caption{Chebyshev Type 1}
  \label{fig:cheby1rs}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=\linewidth]{figs/cheby2-rp-comparison.png}
  \caption{Chebyshev Type 2}
  \label{fig:cheby2rs}
\end{subfigure}
\caption{Comparison of Chebyshev filter rs values}
\label{fig:chebyrs}
\end{figure}

The filter is defined with similar parameters to a Butterworth filter - order,
critical frequencies, and type all have very similar meanings. However,
there are type 1 and 2 Chebyshev filters, with different aims. Additionally,
there is a new parameter \emph{rs}. I will explain these differences here.

Type 1 Chebyshev filters introduce passband ripple, whereas type 2 Chebyshev 
filters introduce stopband ripple. Figure \ref{fig:chebyrs} shows how these
differences manifest in the response of a second order Chebyshev filter.

The parameter \emph{rs} is defined as the maximum ripple permitted below unity
gain. Higher \(rs\) results in more ripple for a type 1 filter, but less
ripple for a part 2 filter, as is demonstrated in figure \ref{fig:chebyrs}.
Introducing more ripple is undesirable as leads to more signal distortion,
however can be advantageous as it reduces the transition width.

\section{Motion Artefact Reduction}

In this section I explore a method which can be used to reduce the effect of 
Motion Artefacts (MAs) on the PPG Signal.

\subsection{Adaptive Noise Cancellation}

Adaptive Noise Cancellation (ANC), as described by Widrow et al.
\cite{Widrow75}, is a technique which allows us to remove noise from a signal,
given we have another signal correlated to the noise in some way. In our 
situation, we know MAs are correlated to motion, so we can use the 
accelerometer to remove MAs. This technique is extremely useful, as it can 
still produce good results when the MAs are at the same frequency as the heart
beat, even if the MAs have a larger amplitude.

%TODO: https://ieeexplore.ieee.org/abstract/document/7867772 this may be
%helpful


\begin{figure}[tbh]
	\centerline{\includegraphics[width=\textwidth]{figs/ANC-concept.png}}
\caption{ANC overall flow}
\label{epsfig}
\end{figure}


An overview of the algorithm follows. We have signal from heartbeat \(s\) that
we want to figure out, but this is contaminated by noise from MAs \(n_0\).
We assume the PPG sensor reading \(p\) is such that \(p=s+n_0\). Additionally,
we have accelerometer sensor readings \(n_1\). We filter \(n_1\), producing
signal \(y\) and subtract this from \(p\), to produce \(z=p-y\). Our aim is to
adjust the filter, such that \(y\) is as close to \(n_0\) as possible. 

The type of filter we adjust is known as a Finite Impulse Response (FIR)
filter. An \(N\)th order filter is defined by \(N\) weights.
These weights are convolved with the signal, hence filtering it.

The adaptive filter aims to choose a filter such that the power of the output 
\(E[z^2]\) is minimized. Given \(s\) is uncorrelated with \(n_0\) and \(n_1\), and \(n_0\)
is correlated with \(n_1\), it can be proven that minimizing the output power
is equivalent to finding \(z=s\).

There are multiple algorithms which exist in order to adaptively filter a
signal. I'll look at two, first describing the least mean squares (LMS) algorithm from
Widrow and Hoff. LMS first initializes all of the filter weights to 0. At each
step, it finds the gradient of the mean square output \(E(z^2)\).
Each weight's gradient describes what would happen to the signal if we kept
using that weight value. So if the gradient of a weight is positive we know
that using that weight again would increase the mean squared output. Hence, at
the end of each step we shift the weights down if the gradient is positive,
and visa versa if the gradient is negative.

LMS takes a parameter - step size \(\mu\), which scales how much we move the
weights by. The equation used to update weights is \[w_{n+1}=w_n-\mu \nabla
E(y^2)[n]\]
where \(W_n\) is the \(n\)th filter weight, and \(\nabla E(y^2)[n]\) is the
\(n\)th weight gradient.

Step size must be chosen very carefully, as if it is too large there is a risk
of LMS missing the solution as it overcompensates for the gradient. If it is
too small, then the algorithm becomes too expensive as we need many more
iterations. The situation is made worse as the ideal step size changes with
respect to the power of the input, making it very difficult to choose a step
size which gives stability.

To solve these stability issues, NLMS was introduced. It is the same as LMS, except you normalize the input power each
iteration. This makes choosing a step size which gives stability a lot easier.

So now we have a stable adaptive filter, which will allow us to tune a filter
that will remove motion noise from our PPG signal.

\section{Heart Rate Calculation}

Now we have removed noise from the signal, we should have a signal 
representing the volume of blood in veins within the arm. As the heart beats,
it sends a wave of blood through the body, forcing more blood through these
veins. Hence, peaks in the PPG signal correspond to heart beats. 

There are multiple approaches to finding heart-rate from our filtered
signals, and I will detail a few here.

\subsection{Local Maxima}

If we can find the peaks in the signal, we can count them up and divide by the
time period we count those peaks within, giving us a heart rate. One way we
can define peaks is as local maxima.

The local maxima in a signal are defined as samples which are larger than both
neighbouring samples. Finding local maxima is an easy problem to solve - 
intuitively, we can create an algorithm which iterates through the samples,
comparing each sample to it's neighbours, which has complexity \(O(n)\).

\subsection{Peak-Peak Standard Deviation Minimization}

Finding the local maxima is a naive approach that doesn't adapt to any problem
specific knowledge. For example, we know heart-rate will not climb above 220
bpm, however the prior solution could report 300 bpm. Additionally, it might
find multiple local peaks around a single heart-beat. 

Ideally, we want to include knowledge about what a normal heart-beat looks
like in our detection algorithm. One thing we can do is look at peak-peak
intervals - the time that passes between heart beats. Surprisingly, this is
normally not consistent - a healthy heart actually beats with some
variation. However, when running it has been found that the heart beats with
very little variation \cite{michael17}, and hence in our case we can assume that the heart
beats regularly. The aim of this method is to use this assumption, along with
minimum and maximum heart-rate to better detect heart-beats.

The method begins by calculating an initial set of peaks, by calculating the
rolling mean of the signal, and marking points above that mean as peaks. Then,
we compute the standard deviation of the time between these peaks (peak-peak
interval). Then, we iteratively increase the rolling mean and again calculate
the peaks, along with
the standard deviation of their intervals. The idea is every time we increase the rolling mean we 
exclude more peaks. Then at the end, the peaks we actually select are the peaks which give a reasonable
heart-rate (in the range 20-240 bpm), and have the smallest standard deviation.

So, we have developed an algorithm that attempts to find a heart-beat with
regular peak-peak intervals, and is within a reasonable range.



\section{Post Processing}

\subsection{Kalman Filter}

So far, we have not considered previous heart-rate readings when considering
the current calculation. This is naive, as heart-rate over the course of a run
follows a very fixed pattern. 

Figure    shows heart-rate over a steady run. It is clear initially heart-rate
ramps up until it reaches a 'steady-state'. From here on the heart-rate
remains pretty constant, not responding to slight changes in exertion.
Finally, the heart-rate decreases rapidly once the run has completed.

The Kalman filter is an algorithm which can compensate for noisy and
inaccurate measurements such as what we get from the PPG signal. It consists
of two phases:
\begin{enumerate}
	\item Prediction step - predict the current heart rate based on the
		previous heart rate, and some model. In this step we can
		incorporate the accelerometer as a reasonable estimator for
		the change in running effort.

	\item Update step - take the actual reading from the PPG signal and combine
		with the output of the prediction step.
\end{enumerate}

The Kalman filter relies on modelling current heart-rate as a Gaussian
distribution with it's standard deviation representing the certainty of the
current estimate.

Kalman gain is the parameter used to weight the measurements against the
prediction. A higher gain assigns more trust to the measurements, meaning the
filter will respond quicker, a low gain produces more smoothing.

\chapter{Evaluation}

\section{Gathering Data}

\subsection{Synchronising Signals}

\section{Filtering}

\section{Motion Artefact Reduction}

\section{Heart Rate Calculation}

\section{Post Processing}

\chapter{Conclusion}

I hope that this rough guide to writing a dissertation is \LaTeX\ has
been helpful and saved you time.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% the bibliography
\addcontentsline{toc}{chapter}{Bibliography}
\bibliography{refs}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% the appendices
\appendix


\chapter{Latex source}

\section{diss.tex}
{\scriptsize\verbatiminput{diss.tex}}

\chapter{Makefile}

\section{makefile}\label{makefile}
{\scriptsize\verbatiminput{makefile.txt}}

\section{refs.bib}
{\scriptsize\verbatiminput{refs.bib}}


\chapter{Project Proposal}

\includepdf[pages=-,pagecommand={},width=\textwidth]{proposal.pdf}

\end{document}
